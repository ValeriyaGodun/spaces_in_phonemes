{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc746d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:58.948725Z",
     "iopub.status.busy": "2026-01-27T11:40:58.948441Z",
     "iopub.status.idle": "2026-01-27T11:40:58.952464Z",
     "shell.execute_reply": "2026-01-27T11:40:58.951726Z",
     "shell.execute_reply.started": "2026-01-27T11:40:58.948702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021f35f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:58.957777Z",
     "iopub.status.busy": "2026-01-27T11:40:58.957212Z",
     "iopub.status.idle": "2026-01-27T11:40:58.992565Z",
     "shell.execute_reply": "2026-01-27T11:40:58.992030Z",
     "shell.execute_reply.started": "2026-01-27T11:40:58.957755Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>phrase</th>\n",
       "      <th>split_phrase</th>\n",
       "      <th>ipa</th>\n",
       "      <th>split_ipa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>取り残され</td>\n",
       "      <td>取り残さ れ</td>\n",
       "      <td>t o ɾʲ i n o k o s a ɾ e</td>\n",
       "      <td>t o ɾʲ i n o k o s a &lt;space&gt; ɾ e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ブスかわ</td>\n",
       "      <td>ブス か わ</td>\n",
       "      <td>b ɯ s ɨ k a w a</td>\n",
       "      <td>b ɯ s ɨ &lt;space&gt; k a &lt;space&gt; w a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>早鐘を打つ</td>\n",
       "      <td>早鐘 を 打つ</td>\n",
       "      <td>h a j a ɡ a n e o ː t s ɨ</td>\n",
       "      <td>h a j a ɡ a n e &lt;space&gt; o &lt;space&gt; ː t s ɨ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>マニラ紙</td>\n",
       "      <td>マニラ 紙</td>\n",
       "      <td>m a ɲ i ɾ a ɕ i</td>\n",
       "      <td>m a ɲ i ɾ a &lt;space&gt; ɕ i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>すいこめば</td>\n",
       "      <td>すいこめ ば</td>\n",
       "      <td>s ɨ i k o m e b a</td>\n",
       "      <td>s ɨ i k o m e &lt;space&gt; b a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id phrase split_phrase                        ipa  \\\n",
       "0   0  取り残され       取り残さ れ   t o ɾʲ i n o k o s a ɾ e   \n",
       "1   1   ブスかわ       ブス か わ            b ɯ s ɨ k a w a   \n",
       "2   2  早鐘を打つ      早鐘 を 打つ  h a j a ɡ a n e o ː t s ɨ   \n",
       "3   3   マニラ紙        マニラ 紙            m a ɲ i ɾ a ɕ i   \n",
       "4   4  すいこめば       すいこめ ば          s ɨ i k o m e b a   \n",
       "\n",
       "                                   split_ipa  \n",
       "0           t o ɾʲ i n o k o s a <space> ɾ e  \n",
       "1            b ɯ s ɨ <space> k a <space> w a  \n",
       "2  h a j a ɡ a n e <space> o <space> ː t s ɨ  \n",
       "3                    m a ɲ i ɾ a <space> ɕ i  \n",
       "4                  s ɨ i k o m e <space> b a  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем данные из CSV файла\n",
    "csv_path = \"train.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb4f7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:58.993738Z",
     "iopub.status.busy": "2026-01-27T11:40:58.993550Z",
     "iopub.status.idle": "2026-01-27T11:40:59.010238Z",
     "shell.execute_reply": "2026-01-27T11:40:59.009717Z",
     "shell.execute_reply.started": "2026-01-27T11:40:58.993721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример после очистки пробелов:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>phrase</th>\n",
       "      <th>split_phrase</th>\n",
       "      <th>ipa</th>\n",
       "      <th>split_ipa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>取り残され</td>\n",
       "      <td>取り残さ れ</td>\n",
       "      <td>toɾʲinokosaɾe</td>\n",
       "      <td>toɾʲinokosa&lt;space&gt;ɾe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ブスかわ</td>\n",
       "      <td>ブス か わ</td>\n",
       "      <td>bɯsɨkawa</td>\n",
       "      <td>bɯsɨ&lt;space&gt;ka&lt;space&gt;wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>早鐘を打つ</td>\n",
       "      <td>早鐘 を 打つ</td>\n",
       "      <td>hajaɡaneoːtsɨ</td>\n",
       "      <td>hajaɡane&lt;space&gt;o&lt;space&gt;ːtsɨ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>マニラ紙</td>\n",
       "      <td>マニラ 紙</td>\n",
       "      <td>maɲiɾaɕi</td>\n",
       "      <td>maɲiɾa&lt;space&gt;ɕi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>すいこめば</td>\n",
       "      <td>すいこめ ば</td>\n",
       "      <td>sɨikomeba</td>\n",
       "      <td>sɨikome&lt;space&gt;ba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id phrase split_phrase            ipa                    split_ipa\n",
       "0   0  取り残され       取り残さ れ  toɾʲinokosaɾe         toɾʲinokosa<space>ɾe\n",
       "1   1   ブスかわ       ブス か わ       bɯsɨkawa       bɯsɨ<space>ka<space>wa\n",
       "2   2  早鐘を打つ      早鐘 を 打つ  hajaɡaneoːtsɨ  hajaɡane<space>o<space>ːtsɨ\n",
       "3   3   マニラ紙        マニラ 紙       maɲiɾaɕi              maɲiɾa<space>ɕi\n",
       "4   4  すいこめば       すいこめ ば      sɨikomeba             sɨikome<space>ba"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Убираем все пробелы из столбцов ipa и split_ipa\n",
    "for col in [\"ipa\", \"split_ipa\"]:\n",
    "    df[col] = df[col].str.replace(\" \", \"\", regex=False)\n",
    "\n",
    "print(\"Пример после очистки пробелов:\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9fbb8a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.011249Z",
     "iopub.status.busy": "2026-01-27T11:40:59.011007Z",
     "iopub.status.idle": "2026-01-27T11:40:59.028810Z",
     "shell.execute_reply": "2026-01-27T11:40:59.028132Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.011228Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датафрейма: (5874, 5)\n",
      "\n",
      "Информация:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5874 entries, 0 to 5873\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            5874 non-null   int64 \n",
      " 1   phrase        5874 non-null   object\n",
      " 2   split_phrase  5874 non-null   object\n",
      " 3   ipa           5874 non-null   object\n",
      " 4   split_ipa     5874 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 229.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Общая информация\n",
    "print(\"Размер датафрейма:\", df.shape)\n",
    "print(\"\\nИнформация:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83655575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.030638Z",
     "iopub.status.busy": "2026-01-27T11:40:59.030116Z",
     "iopub.status.idle": "2026-01-27T11:40:59.044767Z",
     "shell.execute_reply": "2026-01-27T11:40:59.044075Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.030618Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение длины фонем (ipa):\n",
      "count    5874.000000\n",
      "mean       10.615254\n",
      "std         3.056884\n",
      "min         4.000000\n",
      "25%         8.000000\n",
      "50%        10.000000\n",
      "75%        12.000000\n",
      "max        32.000000\n",
      "Name: ipa, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Длины строк в фонемах \n",
    "ipa_lengths = df[\"ipa\"].apply(len)\n",
    "\n",
    "print(\"Распределение длины фонем (ipa):\")\n",
    "print(ipa_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6901962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.045806Z",
     "iopub.status.busy": "2026-01-27T11:40:59.045569Z",
     "iopub.status.idle": "2026-01-27T11:40:59.063044Z",
     "shell.execute_reply": "2026-01-27T11:40:59.062370Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.045777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение количества слов (split_phrase):\n",
      "count    5874.000000\n",
      "mean        2.296902\n",
      "std         0.606200\n",
      "min         2.000000\n",
      "25%         2.000000\n",
      "50%         2.000000\n",
      "75%         2.000000\n",
      "max         7.000000\n",
      "Name: split_phrase, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Количество слов в японской записи предложения (split_phrase)\n",
    "word_counts = df[\"split_phrase\"].str.split().apply(len)\n",
    "print(\"Распределение количества слов (split_phrase):\")\n",
    "print(word_counts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4b069ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.064622Z",
     "iopub.status.busy": "2026-01-27T11:40:59.064406Z",
     "iopub.status.idle": "2026-01-27T11:40:59.083283Z",
     "shell.execute_reply": "2026-01-27T11:40:59.082744Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.064603Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение длины слова (в иероглифах):\n",
      "count    13492.000000\n",
      "mean         2.068485\n",
      "std          1.043233\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          2.000000\n",
      "max          9.000000\n",
      "Name: split_phrase, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Длины отдельных слов по японским символам (иероглифам) в split_phrase\n",
    "all_words = df[\"split_phrase\"].str.split()\n",
    "word_lengths = all_words.explode().str.len()\n",
    "print(\"Распределение длины слова (в иероглифах):\")\n",
    "print(word_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23d0f13c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.084417Z",
     "iopub.status.busy": "2026-01-27T11:40:59.084163Z",
     "iopub.status.idle": "2026-01-27T11:40:59.100532Z",
     "shell.execute_reply": "2026-01-27T11:40:59.099851Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.084391Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение длины фонем (в символах):\n",
      "count    13492.000000\n",
      "mean         4.621554\n",
      "std          2.284612\n",
      "min          1.000000\n",
      "25%          3.000000\n",
      "50%          4.000000\n",
      "75%          6.000000\n",
      "max         18.000000\n",
      "Name: split_ipa, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Длины отдельных слов по символам в split_ipa\n",
    "all_words = df[\"split_ipa\"].str.split(\"<space>\")\n",
    "word_lengths = all_words.explode().str.len()\n",
    "print(\"Распределение длины фонем (в символах):\")\n",
    "print(word_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3484ebb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.102123Z",
     "iopub.status.busy": "2026-01-27T11:40:59.101754Z",
     "iopub.status.idle": "2026-01-27T11:40:59.115475Z",
     "shell.execute_reply": "2026-01-27T11:40:59.114642Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.102101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее количество фонем на один японский символ: 2.234\n"
     ]
    }
   ],
   "source": [
    "# Для всех данных вычислим среднее количество фонем на один японский символ\n",
    "total_ipa_length = df[\"ipa\"].str.len().sum()\n",
    "total_char_count = df[\"phrase\"].str.len().sum()\n",
    "avg_phonemes_per_char = total_ipa_length / total_char_count\n",
    "\n",
    "print(f\"Среднее количество фонем на один японский символ: {avg_phonemes_per_char:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb181f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.116816Z",
     "iopub.status.busy": "2026-01-27T11:40:59.116475Z",
     "iopub.status.idle": "2026-01-27T11:40:59.170447Z",
     "shell.execute_reply": "2026-01-27T11:40:59.169759Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.116786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего предложений: 5874\n",
      "Всего уникальных символов: 1811\n",
      "Максимальная длина фонем: 32, максимальное количество символов в split_phrase: 13\n",
      "Максимальное отношение длины фонем к числу символов: 4.67\n",
      "\n",
      "Будем ограничивать длину одного символа значением 6\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для обучения модели\n",
    "\n",
    "# Создаем функцию, которая разбивает фразу и извлекает отдельные японские символы (иероглифы)\n",
    "def split_phrase_to_symbols(split_phrase: str):\n",
    "    words = split_phrase.split()\n",
    "    symbols = []\n",
    "    word_ids = []\n",
    "    for word_idx, word in enumerate(words):\n",
    "        chars = list(word)\n",
    "        symbols.extend(chars)\n",
    "        word_ids.extend([word_idx] * len(chars))\n",
    "    return words, symbols, word_ids # Возвращает список слов, список символов и список индексов слов для каждого иероглифа\n",
    "\n",
    "\n",
    "# Подготовка данных\n",
    "samples = []    # структура по каждому предложению (уникальные символы, макс. длина фонем и т.д.)\n",
    "symbol_vocab = set()    # множество всех уникальных символов \n",
    "max_ratio = 0.0     # максимальное отношение длины фонем к числу символов (от него зависит ограничение на длину сегмента)\n",
    "max_ipa_len = 0     # максимальная длина фонем\n",
    "max_symbol_len = 0   # максимальное количество символов в split_phrase\n",
    "\n",
    "# Обработка каждого предложения из датафрейма\n",
    "for row in df.itertuples(index=False):\n",
    "    words, symbols, word_ids = split_phrase_to_symbols(row.split_phrase)    \n",
    "    if not symbols or not isinstance(row.ipa, str) or len(row.ipa) == 0:    \n",
    "        continue\n",
    "\n",
    "    # Вычисляем отношение длины фонем к количеству символов для определения максимальной длины\n",
    "    ipa_chars = list(row.ipa)  \n",
    "    ratio = len(ipa_chars) / len(symbols)   # сколько фонем приходится на один японский символ\n",
    "    max_ratio = max(max_ratio, ratio)  \n",
    "    max_ipa_len = max(max_ipa_len, len(ipa_chars))  \n",
    "    max_symbol_len = max(max_symbol_len, len(symbols))  \n",
    "\n",
    "    # Сохраняем данные для каждого предложения\n",
    "    samples.append(\n",
    "        {\n",
    "            \"id\": int(row.id),\n",
    "            \"split_phrase\": row.split_phrase,\n",
    "            \"words\": words,\n",
    "            \"symbols\": symbols,\n",
    "            \"word_ids\": word_ids,  # индекс слова для каждого символа\n",
    "            \"ipa_chars\": ipa_chars,  # фонемная строка, разбитая посимвольно\n",
    "            \"ipa_str\": row.ipa,\n",
    "            \"split_ipa_true\": row.split_ipa,  # разметка только для оценки\n",
    "        }\n",
    "    )\n",
    "    symbol_vocab.update(symbols)\n",
    "\n",
    "\n",
    "max_chunk_len = max(int(np.ceil(max_ratio)) + 1, 4)\n",
    "\n",
    "print(f\"Всего предложений: {len(samples)}\")\n",
    "print(f\"Всего уникальных символов: {len(symbol_vocab)}\")\n",
    "print(f\"Максимальная длина фонем: {max_ipa_len}, максимальное количество символов в split_phrase: {max_symbol_len}\")\n",
    "print(f\"Максимальное отношение длины фонем к числу символов: {max_ratio:.2f}\")\n",
    "\n",
    "print(f\"\\nБудем ограничивать длину одного символа значением {max_chunk_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e174c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.173166Z",
     "iopub.status.busy": "2026-01-27T11:40:59.172927Z",
     "iopub.status.idle": "2026-01-27T11:40:59.199758Z",
     "shell.execute_reply": "2026-01-27T11:40:59.199146Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.173147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Реализация скрытой полу-марковской модели (HSMM) для сегментации фонем\n",
    "# Модель обучает распределение длины сегментов фонем для каждого японского символа (иероглифа)\n",
    "\n",
    "# Функция для суммирования вероятностей в логарифмическом пространстве\n",
    "def logsumexp_pair(a, b):\n",
    "    if not math.isfinite(a):\n",
    "        return b\n",
    "    if not math.isfinite(b):\n",
    "        return a\n",
    "    if a > b:\n",
    "        return a + math.log1p(math.exp(b - a))\n",
    "    return b + math.log1p(math.exp(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d669a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для инициализации длин сегментов фонем для каждого символа\n",
    "def greedy_length_initialization(num_symbols: int, ipa_len: int, max_len: int):\n",
    "    # num_symbols - количество японских символов\n",
    "    # ipa_len - общая длина фонемной последовательности\n",
    "    # max_len - максимальная длина сегмента фонем для одного символа\n",
    "    lengths = []  \n",
    "    remaining = ipa_len \n",
    "    for idx in range(num_symbols):\n",
    "        symbols_left = num_symbols - idx\n",
    "        if symbols_left == 0:\n",
    "            break\n",
    "\n",
    "        # Вычисляем минимальную и максимальную допустимую длину для текущего символа\n",
    "        min_len = max(1, remaining - (symbols_left - 1) * max_len) \n",
    "        max_len_allowed = min(max_len, remaining - (symbols_left - 1)) \n",
    "        if max_len_allowed < min_len:\n",
    "            max_len_allowed = min_len\n",
    "\n",
    "        # Берем среднее значение с округлением\n",
    "        avg = remaining / symbols_left\n",
    "        length = int(round(avg))\n",
    "        length = max(min_len, min(max_len_allowed, length)) \n",
    "        lengths.append(length)\n",
    "        remaining -= length\n",
    "\n",
    "    # Распределяем остаток обратно по символам, если он есть\n",
    "    if remaining != 0:\n",
    "        for idx in range(len(lengths) - 1, -1, -1):\n",
    "            take = min(max_len - lengths[idx], remaining)\n",
    "            lengths[idx] += take\n",
    "            remaining -= take\n",
    "            if remaining == 0:\n",
    "                break\n",
    "    if remaining != 0:\n",
    "        raise ValueError(\"Не удалось корректно разложить длину IPA по иероглифам\")\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ba020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скрытая полу-марковская модель для сегментации фонем\n",
    "class LengthHSMM:\n",
    "    # Инициализация модели\n",
    "    def __init__(self, symbol_vocab, max_len=6, length_prior=0.1):\n",
    "        # symbol_vocab - множество всех уникальных японских символов\n",
    "        # max_len - максимальная длина сегмента для одного символа\n",
    "        # length_prior - априорная вероятность для сглаживания распределений\n",
    "        self.symbol_vocab = symbol_vocab\n",
    "        self.max_len = max_len\n",
    "        self.length_prior = length_prior\n",
    "        self.length_log_probs = {}  # Логарифмы вероятностей длин для каждого символа\n",
    "        self.initialized = False # Флаг, указывающий, инициализирована ли модель (для контроля состояния модели)\n",
    "\n",
    "    # Инициализация параметров модели на основе жадной сегментации - подсчитывает частоты длин сегментов для каждого японского символа\n",
    "    def initialize_params(self, samples):\n",
    "        counts = defaultdict(lambda: np.full(self.max_len, self.length_prior)) \n",
    "        for sample in samples:\n",
    "            symbols = sample[\"symbols\"]\n",
    "            ipa_len = len(sample[\"ipa_chars\"])\n",
    "            if not symbols:\n",
    "                continue\n",
    "            # Получаем начальную сегментацию жадным алгоритмом\n",
    "            lengths = greedy_length_initialization(len(symbols), ipa_len, self.max_len)\n",
    "            # Подсчитываем частоты длин фонем для каждого символа\n",
    "            for ch, length in zip(symbols, lengths):\n",
    "                if 1 <= length <= self.max_len:\n",
    "                    counts[ch][length - 1] += 1.0\n",
    "        # Нормализуем частоты в вероятности и сохраняем в логарифмическом виде\n",
    "        for ch in self.symbol_vocab:\n",
    "            if ch not in counts:\n",
    "                counts[ch] = np.full(self.max_len, self.length_prior)\n",
    "            probs = counts[ch] / counts[ch].sum()\n",
    "            self.length_log_probs[ch] = np.log(probs)\n",
    "        self.initialized = True\n",
    "\n",
    "    # Получение логарифмических вероятностей длин сегментов фонем для заданного японского символа\n",
    "    def _get_log_length_probs(self, char):\n",
    "        if char not in self.length_log_probs: \n",
    "            self.symbol_vocab.add(char)\n",
    "            uniform = np.full(self.max_len, 1.0 / self.max_len)\n",
    "            self.length_log_probs[char] = np.log(uniform)\n",
    "        return self.length_log_probs[char]\n",
    "\n",
    "    # Прямой проход алгоритма для вычисления вероятностей\n",
    "    def _forward_pass(self, symbols, obs_len):\n",
    "        # obs_len - длина фонемной последовательности\n",
    "        T = len(symbols)    \n",
    "        alpha = np.full((T + 1, obs_len + 1), -np.inf) \n",
    "        alpha[0, 0] = 0.0   \n",
    "        for t in range(T):\n",
    "            char = symbols[t]\n",
    "            log_len = self._get_log_length_probs(char)\n",
    "            # Обработка каждой позиции в фонемах\n",
    "            for pos in range(obs_len + 1):\n",
    "                current = alpha[t, pos]\n",
    "                if not math.isfinite(current):\n",
    "                    continue\n",
    "                # Перебираем возможные длины сегмента для текущего символа\n",
    "                max_d = min(self.max_len, obs_len - pos) \n",
    "                for d in range(1, max_d + 1): \n",
    "                    log_prob = log_len[d - 1]\n",
    "                    if not math.isfinite(log_prob):\n",
    "                        continue\n",
    "                    next_pos = pos + d\n",
    "                    # Обновляем вероятность для численной устойчивости\n",
    "                    alpha[t + 1, next_pos] = logsumexp_pair(\n",
    "                        alpha[t + 1, next_pos], current + log_prob\n",
    "                    )\n",
    "        return alpha\n",
    "\n",
    "    # Обратный проход алгоритма для вычисления вероятностей\n",
    "    def _backward_pass(self, symbols, obs_len):\n",
    "        T = len(symbols)\n",
    "        beta = np.full((T + 1, obs_len + 1), -np.inf)\n",
    "        beta[T, obs_len] = 0.0  \n",
    "        for t in range(T - 1, -1, -1):\n",
    "            char = symbols[t] \n",
    "            log_len = self._get_log_length_probs(char)\n",
    "            for pos in range(obs_len, -1, -1):  # Идем от конца к началу\n",
    "                max_d = min(self.max_len, obs_len - pos)\n",
    "                if max_d == 0:  \n",
    "                    continue\n",
    "                value = -np.inf\n",
    "                # Перебираем возможные длины сегмента\n",
    "                for d in range(1, max_d + 1):\n",
    "                    next_pos = pos + d\n",
    "                    log_prob = log_len[d - 1]\n",
    "                    if not math.isfinite(log_prob) or not math.isfinite(\n",
    "                        beta[t + 1, next_pos]\n",
    "                    ):\n",
    "                        continue\n",
    "                    value = logsumexp_pair(value, log_prob + beta[t + 1, next_pos])\n",
    "                beta[t, pos] = value\n",
    "        return beta\n",
    "\n",
    "    # E-шаг алгоритма EM (Expectation и Maximization) - вычисление ожидаемых частот длин сегментов для каждого символа на основе текущих параметров модели   \n",
    "    def expectation_step(self, samples):\n",
    "        length_counts = defaultdict(lambda: np.zeros(self.max_len))\n",
    "        total_loglike = 0.0 \n",
    "        for sample in samples:\n",
    "            symbols = sample[\"symbols\"]\n",
    "            obs_len = len(sample[\"ipa_chars\"])\n",
    "            if not symbols:\n",
    "                continue\n",
    "            # Выполняем forward и backward проходы\n",
    "            alpha = self._forward_pass(symbols, obs_len)\n",
    "            beta = self._backward_pass(symbols, obs_len)\n",
    "            logZ = alpha[len(symbols), obs_len]  # Нормализующая константа\n",
    "            if not math.isfinite(logZ):\n",
    "                continue\n",
    "            total_loglike += logZ\n",
    "            # Вычисляем апостериорные вероятности для каждого символа и позиции\n",
    "            for t, char in enumerate(symbols):\n",
    "                log_len = self._get_log_length_probs(char)\n",
    "                for pos in range(obs_len + 1):\n",
    "                    if not math.isfinite(alpha[t, pos]):\n",
    "                        continue\n",
    "                    max_d = min(self.max_len, obs_len - pos)\n",
    "                    for d in range(1, max_d + 1):\n",
    "                        next_pos = pos + d\n",
    "                        log_prob = log_len[d - 1]\n",
    "                        if not math.isfinite(log_prob) or not math.isfinite(\n",
    "                            beta[t + 1, next_pos]\n",
    "                        ):\n",
    "                            continue\n",
    "                        contrib = alpha[t, pos] + log_prob + beta[t + 1, next_pos] - logZ\n",
    "                        aposterior = math.exp(contrib)\n",
    "                        if aposterior > 0:\n",
    "                            length_counts[char][d - 1] += aposterior\n",
    "        return length_counts, total_loglike\n",
    "\n",
    "    # M-шаг алгоритма EM - обновление параметров модели (вероятности длин для каждого символа) на основе ожидаемых частот\n",
    "    def maximization_step(self, length_counts):\n",
    "        for ch in self.symbol_vocab:\n",
    "            counts = length_counts[ch] + self.length_prior \n",
    "            probs = counts / counts.sum()\n",
    "            self.length_log_probs[ch] = np.log(probs)\n",
    "\n",
    "    # Обучение модели алгоритмом EM, выполняем итерации E-шага и M-шага до сходимости\n",
    "    def fit(self, samples, n_iter=10, verbose=True):\n",
    "        if not self.initialized:\n",
    "            self.initialize_params(samples)\n",
    "        history = []\n",
    "        for iteration in range(1, n_iter + 1):\n",
    "            length_counts, total_loglike = self.expectation_step(samples)\n",
    "            self.maximization_step(length_counts)\n",
    "            avg_ll = total_loglike / max(len(samples), 1)\n",
    "            history.append(avg_ll)\n",
    "            if verbose:\n",
    "                print(f\"Итерация {iteration}: средний log-likelihood = {avg_ll:.4f}\")\n",
    "        return history\n",
    "\n",
    "    # Декодирование с помощью алгоритма Витерби (находит наиболее вероятную последовательность)\n",
    "    def decode(self, sample):\n",
    "        # Подготовка данных\n",
    "        symbols = sample[\"symbols\"]\n",
    "        obs_len = len(sample[\"ipa_chars\"])\n",
    "        T = len(symbols)\n",
    "        if T == 0:\n",
    "            return []\n",
    "        # Динамическое программирование для поиска оптимального пути\n",
    "        dp = np.full((T + 1, obs_len + 1), -np.inf)\n",
    "        backptr = [[None] * (obs_len + 1) for _ in range(T + 1)]\n",
    "        dp[0, 0] = 0.0 \n",
    "        # Прямым проходом ищем лучший путь\n",
    "        for t in range(T): \n",
    "            char = symbols[t]\n",
    "            log_len = self._get_log_length_probs(char) \n",
    "            for pos in range(obs_len + 1): \n",
    "                current = dp[t, pos]\n",
    "                if not math.isfinite(current):\n",
    "                    continue\n",
    "                max_d = min(self.max_len, obs_len - pos)\n",
    "                for d in range(1, max_d + 1):\n",
    "                    log_prob = log_len[d - 1]\n",
    "                    if not math.isfinite(log_prob):\n",
    "                        continue\n",
    "                    next_pos = pos + d\n",
    "                    score = current + log_prob  \n",
    "                    # Обновляем лучший путь\n",
    "                    if score > dp[t + 1, next_pos]:\n",
    "                        dp[t + 1, next_pos] = score\n",
    "                        backptr[t + 1][next_pos] = (pos, d)\n",
    "        if not math.isfinite(dp[T, obs_len]): # Проверяем, что найден путь от начала до конца\n",
    "            return None\n",
    "        # Восстанавливаем путь обратным проходом\n",
    "        lengths = [0] * T\n",
    "        pos = obs_len\n",
    "        for t in range(T, 0, -1):\n",
    "            prev = backptr[t][pos]\n",
    "            if prev is None:\n",
    "                return None\n",
    "            prev_pos, d = prev\n",
    "            lengths[t - 1] = d\n",
    "            pos = prev_pos\n",
    "        return lengths # Возвращаем список длин сегментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb4733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:40:59.201204Z",
     "iopub.status.busy": "2026-01-27T11:40:59.200941Z",
     "iopub.status.idle": "2026-01-27T11:42:58.327110Z",
     "shell.execute_reply": "2026-01-27T11:42:58.326374Z",
     "shell.execute_reply.started": "2026-01-27T11:40:59.201173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация 1: средний log-likelihood = -1.6894\n",
      "Итерация 2: средний log-likelihood = -1.5082\n",
      "Итерация 3: средний log-likelihood = -1.4240\n",
      "Итерация 4: средний log-likelihood = -1.3494\n",
      "Итерация 5: средний log-likelihood = -1.2712\n",
      "Итерация 6: средний log-likelihood = -1.1878\n",
      "Итерация 7: средний log-likelihood = -1.1041\n",
      "Итерация 8: средний log-likelihood = -1.0277\n",
      "Итерация 9: средний log-likelihood = -0.9644\n",
      "Итерация 10: средний log-likelihood = -0.9158\n",
      "Итерация 11: средний log-likelihood = -0.8802\n",
      "Итерация 12: средний log-likelihood = -0.8539\n",
      "Итерация 13: средний log-likelihood = -0.8334\n",
      "Итерация 14: средний log-likelihood = -0.8166\n",
      "Итерация 15: средний log-likelihood = -0.8027\n",
      "Итерация 16: средний log-likelihood = -0.7910\n",
      "Итерация 17: средний log-likelihood = -0.7812\n",
      "Итерация 18: средний log-likelihood = -0.7731\n",
      "Итерация 19: средний log-likelihood = -0.7665\n",
      "Итерация 20: средний log-likelihood = -0.7610\n",
      "Итерация 21: средний log-likelihood = -0.7565\n",
      "Итерация 22: средний log-likelihood = -0.7528\n",
      "Итерация 23: средний log-likelihood = -0.7497\n",
      "Итерация 24: средний log-likelihood = -0.7470\n",
      "Итерация 25: средний log-likelihood = -0.7448\n",
      "Итерация 26: средний log-likelihood = -0.7430\n",
      "Итерация 27: средний log-likelihood = -0.7414\n",
      "Итерация 28: средний log-likelihood = -0.7400\n",
      "Итерация 29: средний log-likelihood = -0.7388\n",
      "Итерация 30: средний log-likelihood = -0.7378\n",
      "Итерация 31: средний log-likelihood = -0.7368\n",
      "Итерация 32: средний log-likelihood = -0.7359\n",
      "Итерация 33: средний log-likelihood = -0.7350\n",
      "Итерация 34: средний log-likelihood = -0.7342\n",
      "Итерация 35: средний log-likelihood = -0.7334\n",
      "Итерация 36: средний log-likelihood = -0.7328\n",
      "Итерация 37: средний log-likelihood = -0.7323\n",
      "Итерация 38: средний log-likelihood = -0.7318\n",
      "Итерация 39: средний log-likelihood = -0.7315\n",
      "Итерация 40: средний log-likelihood = -0.7311\n",
      "Итерация 41: средний log-likelihood = -0.7308\n",
      "Итерация 42: средний log-likelihood = -0.7305\n",
      "Итерация 43: средний log-likelihood = -0.7302\n",
      "Итерация 44: средний log-likelihood = -0.7299\n",
      "Итерация 45: средний log-likelihood = -0.7295\n",
      "Итерация 46: средний log-likelihood = -0.7291\n",
      "Итерация 47: средний log-likelihood = -0.7286\n",
      "Итерация 48: средний log-likelihood = -0.7283\n",
      "Итерация 49: средний log-likelihood = -0.7280\n",
      "Итерация 50: средний log-likelihood = -0.7278\n"
     ]
    }
   ],
   "source": [
    "# Создание модели HSMM\n",
    "hsmm = LengthHSMM(symbol_vocab, max_len=max_chunk_len, length_prior=0.2) # length_prior - параметр сглаживания для предотвращения нулевых вероятностей\n",
    "\n",
    "# Обучение модели на 50 итерациях\n",
    "training_history = hsmm.fit(samples, n_iter=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ca018f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:42:58.328721Z",
     "iopub.status.busy": "2026-01-27T11:42:58.328490Z",
     "iopub.status.idle": "2026-01-27T11:42:58.336302Z",
     "shell.execute_reply": "2026-01-27T11:42:58.335581Z",
     "shell.execute_reply.started": "2026-01-27T11:42:58.328700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Функции для декодирования и построения предсказаний\n",
    "\n",
    "# Функция для равномерного распределения длин сегментов между символами, используется как запасной вариант\n",
    "def uniform_lengths(total_len: int, num_symbols: int, max_len: int):\n",
    "    # Проверка входных данных\n",
    "    if num_symbols == 0:\n",
    "        return []\n",
    "    if max_len <= 0:\n",
    "        raise ValueError(\"max_len должен быть положительным\")\n",
    "    # Для каждого символа вычисляем минимальную и максимальную допустимую длину\n",
    "    lengths = []\n",
    "    remaining = total_len\n",
    "    for idx in range(num_symbols):\n",
    "        symbols_left = num_symbols - idx - 1\n",
    "        min_len = max(0, remaining - symbols_left * max_len)\n",
    "        max_len_allowed = min(max_len, remaining)\n",
    "        if max_len_allowed < min_len:\n",
    "            max_len_allowed = min_len\n",
    "        # Вычисляем среднюю длину для оставшихся символов\n",
    "        denom = symbols_left + 1\n",
    "        avg = remaining / denom if denom > 0 else remaining\n",
    "        length = int(round(avg))\n",
    "        length = max(min_len, min(max_len_allowed, length))\n",
    "        lengths.append(length)\n",
    "        remaining -= length\n",
    "    return lengths\n",
    "\n",
    "# Функция для построения строки split_ipa из длин сегментов\n",
    "# Объединяет сегменты фонем, принадлежащие одному слову, разделяя слова маркером <space>\n",
    "def build_split_from_lengths(sample, lengths):\n",
    "    ipa_chars = sample[\"ipa_chars\"]\n",
    "    word_ids = sample[\"word_ids\"]\n",
    "    pos = 0\n",
    "    chunks_per_word = defaultdict(list)\n",
    "    # Группируем сегменты по словам\n",
    "    for length, word_idx in zip(lengths, word_ids): \n",
    "        chunk = \"\".join(ipa_chars[pos : pos + length])\n",
    "        pos += length \n",
    "        chunks_per_word[word_idx].append(chunk) \n",
    "    # Объединяем сегменты внутри каждого слова\n",
    "    words = []\n",
    "    for w_idx in range(len(sample[\"words\"])): \n",
    "        words.append(\"\".join(chunks_per_word.get(w_idx, []))) \n",
    "    return \"<space>\".join(words) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ca306e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:55:17.169682Z",
     "iopub.status.busy": "2026-01-27T11:55:17.168954Z",
     "iopub.status.idle": "2026-01-27T11:55:17.725150Z",
     "shell.execute_reply": "2026-01-27T11:55:17.724373Z",
     "shell.execute_reply.started": "2026-01-27T11:55:17.169652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Декодирование всех предложений с помощью обученной модели\n",
    "pred_rows = []\n",
    "failed_decodes = 0\n",
    "for sample in samples:\n",
    "    lengths = hsmm.decode(sample)\n",
    "    # Проверяем корректность декодирования\n",
    "    if lengths is None or sum(lengths) != len(sample[\"ipa_chars\"]):\n",
    "        failed_decodes += 1\n",
    "        # Используем равномерное распределение как запасной вариант\n",
    "        lengths = uniform_lengths(len(sample[\"ipa_chars\"]), len(sample[\"symbols\"]), hsmm.max_len)\n",
    "    split_pred = build_split_from_lengths(sample, lengths)\n",
    "    pred_rows.append(\n",
    "        {\n",
    "            \"id\": sample[\"id\"],\n",
    "            \"split_phrase\": sample[\"split_phrase\"],\n",
    "            \"split_ipa_pred\": split_pred,\n",
    "            \"split_ipa_true\": sample[\"split_ipa_true\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ee7f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:55:21.877236Z",
     "iopub.status.busy": "2026-01-27T11:55:21.876735Z",
     "iopub.status.idle": "2026-01-27T11:55:21.900076Z",
     "shell.execute_reply": "2026-01-27T11:55:21.899536Z",
     "shell.execute_reply.started": "2026-01-27T11:55:21.877208Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary F1-score: 0.8763\n"
     ]
    }
   ],
   "source": [
    "# Функция для подсчета Boundary F1-score - точность определения границ между словами\n",
    "def ipa_boundaries(split_str: str):\n",
    "    parts = split_str.split(\"<space>\")\n",
    "    offsets = []\n",
    "    acc = 0\n",
    "    for part in parts[:-1]:  # Последний сегмент не имеет границы после себя\n",
    "        acc += len(part)\n",
    "        offsets.append(acc)\n",
    "    return set(offsets)\n",
    "\n",
    "# Вычисляем F1\n",
    "tp = 0\n",
    "pred_total = 0\n",
    "true_total = 0\n",
    "\n",
    "for row in pred_df.itertuples():\n",
    "    true_bounds = ipa_boundaries(row.split_ipa_true)\n",
    "    pred_bounds = ipa_boundaries(row.split_ipa_pred)\n",
    "    tp += len(true_bounds & pred_bounds)\n",
    "    pred_total += len(pred_bounds)\n",
    "    true_total += len(true_bounds)\n",
    "\n",
    "boundary_f1 = (2 * tp / (pred_total + true_total)) if (pred_total + true_total) > 0 else 0.0\n",
    "\n",
    "print(f\"Boundary F1-score: {boundary_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc69b1a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T11:55:54.139653Z",
     "iopub.status.busy": "2026-01-27T11:55:54.138884Z",
     "iopub.status.idle": "2026-01-27T11:55:54.148520Z",
     "shell.execute_reply": "2026-01-27T11:55:54.147840Z",
     "shell.execute_reply.started": "2026-01-27T11:55:54.139623Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split_phrase</th>\n",
       "      <th>split_ipa_pred</th>\n",
       "      <th>split_ipa_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>取り残さ れ</td>\n",
       "      <td>toɾʲinokosa&lt;space&gt;ɾe</td>\n",
       "      <td>toɾʲinokosa&lt;space&gt;ɾe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ブス か わ</td>\n",
       "      <td>bɯsɨ&lt;space&gt;ka&lt;space&gt;wa</td>\n",
       "      <td>bɯsɨ&lt;space&gt;ka&lt;space&gt;wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>早鐘 を 打つ</td>\n",
       "      <td>hajaɡane&lt;space&gt;o&lt;space&gt;ːtsɨ</td>\n",
       "      <td>hajaɡane&lt;space&gt;o&lt;space&gt;ːtsɨ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>マニラ 紙</td>\n",
       "      <td>maɲiɾa&lt;space&gt;ɕi</td>\n",
       "      <td>maɲiɾa&lt;space&gt;ɕi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>すいこめ ば</td>\n",
       "      <td>sɨikome&lt;space&gt;ba</td>\n",
       "      <td>sɨikome&lt;space&gt;ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>5864</td>\n",
       "      <td>プレイ 中</td>\n",
       "      <td>pɯɾeː&lt;space&gt;tɕɨː</td>\n",
       "      <td>pɯɾeː&lt;space&gt;tɕɨː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>5865</td>\n",
       "      <td>ほこっ た</td>\n",
       "      <td>hokot&lt;space&gt;ːa</td>\n",
       "      <td>hokotː&lt;space&gt;a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>5866</td>\n",
       "      <td>いかに し て</td>\n",
       "      <td>ikaɲi&lt;space&gt;ɕi&lt;space&gt;te</td>\n",
       "      <td>ikaɲi&lt;space&gt;ɕi&lt;space&gt;te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>5867</td>\n",
       "      <td>草木 も なびく</td>\n",
       "      <td>kɯsaci&lt;space&gt;mo&lt;space&gt;nabʲikɯ</td>\n",
       "      <td>kɯsaci&lt;space&gt;mo&lt;space&gt;nabʲikɯ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>5868</td>\n",
       "      <td>ステップ アップ</td>\n",
       "      <td>sɨtepːɯ&lt;space&gt;apːɯ</td>\n",
       "      <td>sɨtepːɯ&lt;space&gt;apːɯ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5869 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id split_phrase                 split_ipa_pred  \\\n",
       "0        0       取り残さ れ           toɾʲinokosa<space>ɾe   \n",
       "1        1       ブス か わ         bɯsɨ<space>ka<space>wa   \n",
       "2        2      早鐘 を 打つ    hajaɡane<space>o<space>ːtsɨ   \n",
       "3        3        マニラ 紙                maɲiɾa<space>ɕi   \n",
       "4        4       すいこめ ば               sɨikome<space>ba   \n",
       "...    ...          ...                            ...   \n",
       "5864  5864        プレイ 中               pɯɾeː<space>tɕɨː   \n",
       "5865  5865        ほこっ た                 hokot<space>ːa   \n",
       "5866  5866      いかに し て        ikaɲi<space>ɕi<space>te   \n",
       "5867  5867     草木 も なびく  kɯsaci<space>mo<space>nabʲikɯ   \n",
       "5868  5868     ステップ アップ             sɨtepːɯ<space>apːɯ   \n",
       "\n",
       "                     split_ipa_true  \n",
       "0              toɾʲinokosa<space>ɾe  \n",
       "1            bɯsɨ<space>ka<space>wa  \n",
       "2       hajaɡane<space>o<space>ːtsɨ  \n",
       "3                   maɲiɾa<space>ɕi  \n",
       "4                  sɨikome<space>ba  \n",
       "...                             ...  \n",
       "5864               pɯɾeː<space>tɕɨː  \n",
       "5865                 hokotː<space>a  \n",
       "5866        ikaɲi<space>ɕi<space>te  \n",
       "5867  kɯsaci<space>mo<space>nabʲikɯ  \n",
       "5868             sɨtepːɯ<space>apːɯ  \n",
       "\n",
       "[5869 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(-5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14180930,
     "sourceId": 118407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
